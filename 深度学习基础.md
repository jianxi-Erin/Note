# 深度学习基础

## 环境搭建
1. 安装Python

2. 安装Anaconda(miniconda)
```sh
# 使用conda管理虚拟环境

# 创建虚拟环境
conda create -n `env-name` `python=版本` [-c 镜像地址]
# 删除建虚拟环境
conda remove -n `env-name` --all
# 添加源
# channels:
#   - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
#   - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
#   - https://mirrors.ustc.edu.cn/anaconda/pkgs/free
#   - https://mirrors.ustc.edu.cn/anaconda/pkgs/main

conda config --add channels 通道地址
# 删除源
conda config --remove channels 通道地址
# 查看源
conda config --show channels
# 安装时显示安装源
conda config --set show_channel_urls yes


# 查看环境列表
conda env list

# 配置powershell正确显示(环境名)
conda init powershell
conda config --set auto_activate_base false



#激活某个虚拟环境(*)
conda activate env_name
# 退出某个虚拟环境(*)
conda deactivate

# 使用pip安装/卸载虚拟环境包
pip install/uninstall 包[=版本号] [-i 源链接]

pip install -r "requirements.txt文件" [-i 源]
# 更新包
pip install --upgrade 包
#查看安装的包 
pip list

# conda install/uninstall 包名[=版本号] [-i 源链接]
```
3. 安装CUDA驱动/运行环境
```sh
# 1. 确定显卡为Nvidia系列
Windows: 使用组合键`Ctrl+Shift+ESC`打开任务管理器，选择`性能`->`GPU1`查看显卡型号

# 2. 安装显卡驱动
官网安装

# 3. 安装CUDA
确定cuda最高版本  nvidia-smi # 或 打开Nvidia控制面板->系统信息->组件
安装 conda install cuda -c nvidia/label/cuda-版本 #或 官网安装
检查安装是否成功 nvcc --version 

# 4. 安装cuDNN
确定cudnn版本 conda search cudnn --info # 或 官网查询
安装 conda install cudaa=版本 
验证安装 nvidia-smi 

```
4. Windows安装pytorch和cudnn
```url 
安装地址:
https://pytorch.org/get-started/locally/
```
```sh
# 激活conda环境


# conda安装 -c 镜像源
#cpu版本
conda install pytorch torchvision torchaudio cpuonly -c pytorch
# cuda版本 # 如果未安装cuda和cudnn会自动安装
conda install pytorch torchvision torchaudio pytorch-cuda=版本号 -c pytorch -c nvidia


# pip安装

#cpu版本
pip3 install torch torchvision torchaudio
# cuda版本  #如果未安装cuda和cudnn会自动安装
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu版本号

```
5. 创建Tensorflow环境
```python
conda create -n tensorflow_env python=3.9
conda activate tensorflow_env
pip install tensorflow==1.13.1
pip install keras==2.2.4
pip install matplotlib
pip install opencv-python
pip install numpy
```

6. 常用数据集
```
飞桨数据集 https://aistudio.baidu.com/datasetoverview
kaggle数据集 https://www.kaggle.com/datasets
```

## 常见名词

- **特征（Feature）**：用于描述数据样本的属性或属性值，是机器学习模型的输入变量。例如，在房价预测中，房屋的面积、房间数量等都是特征。
- **标签（Label）**：与特征相对应的输出变量，是模型需要预测的目标值。例如，在房价预测中，房屋的价格就是标签。
- **数据集（Dataset）**：用于训练和测试模型的数据集合，通常包含特征和标签。
- **训练集（Training Set）**：用于训练模型的数据集，模型通过学习训练集中的特征和标签之间的关系来构建模型。
- **验证集（Validation Set）**：用于调整模型超参数和评估模型性能的数据集，帮助防止拟过合。
- **测试集（Test Set）**：用于最终评估模型性能的数据集，模型在测试集上的表现通常代表其在实际应用中的性能。
- **模型（Model）**：通过学习数据集中的特征和标签之间的关系而构建的数学模型，用于对新的数据进行预测或分类。
- **算法（Algorithm）**：用于构建模型的方法或过程，例如线性回归、决策树、神经网络等。
- **过拟合（Overfitting）**：模型在训练集上表现很好，但在测试集上表现较差的现象，通常是由于模型过于复杂导致的。
- **欠拟合（Underfitting）**：模型在训练集上表现较差的现象，通常是由于模型过于简单导致的。
- **损失函数（Loss Function）**：用于衡量模型预测值与真实值之间差异的函数，模型的目标是通过优化损失函数来提高预测精度。
- **优化算法（Optimization Algorithm）**：用于最小化损失函数的算法，例如梯度下降法。
- **超参数（Hyperparameter）**：在模型训练之前需要手动设置的参数，例如学习率、迭代次数等。
- **参数（Parameter）**：模型在训练过程中自动学习的参数，例如线性回归中的权重和偏置。
- **正则化（Regularization）**：通过在损失函数中添加惩罚项来防止过拟合的技术，常见的有L1正则化和L2正则化。
- **监督学习（Supervised Learning）**：模型通过学习带标签的数据来构建模型的学习方式，例如分类和回归。
- **无监督学习（Unsupervised Learning）**：模型学习通过无标签的数据来发现数据中的结构或模式的学习方式，例如聚类和降维。
- **半监督学习（Semi-supervised Learning）**：模型通过学习少量带标签的数据和大量无标签的数据来构建模型的学习方式。
- **强化学习（Reinforcement Learning）**：模型通过与环境的交互来学习最优策略的学习方式，通过奖励和惩罚来调整模型的行为。
- **分类（Classification）**：监督学习的一种任务，目标是将数据划分为不同的类别，例如垃圾邮件检测。
- **回归（Regression）**：监督学习的一种任务，目标是预测一个连续的数值，例如房价预测。
- **聚类（Clustering）**：无监督学习的一种任务，目标是将数据划分为不同的簇，使得簇内的数据相似度高，簇间的相似度低。
- **降维（Dimensionality Reduction）**：无监督学习的一种任务，目标是将高维数据映射到低维空间，同时保留数据的主要信息，例如主成分分析（PCA）。
- **准确率（Accuracy）**：分类模型中，预测正确的样本数占总样本数的比例。
- **召回率（Recall）**：在分类模型中，真正例被正确预测的比例。
- **精确率（Precision）**：在分类模型中，被预测为正例样本的中真正例的比例。
- **F1分数（F1 Score）**：精确率和召回率的调和平均值，用于综合评估分类模型的性能。
- **混淆矩阵（Confusion Matrix）**：用于评估分类模型性能的矩阵，包含真正例、假正例、真负例和假负例的数量。
- **ROC曲线（Receiver Operating Characteristic Curve）**：用于评估分类模型性能的曲线，横轴为假正例率，纵轴为真正例率。
- **AUC值（Area Under the ROC Curve）**：ROC曲线下的面积，用于衡量分类模型的性能，值越大表示模型性能越好。
- **混淆矩阵（Confusion Matrix）**：用于评估分类模型性能的矩阵，记录了模型预测结果与真实标签之间的关系。通常包含以下四个基本指标：
    - **真正例（True Positive, TP）**：模型正确预测为正类的样本数。
    - **假正例（False Positive, FP）**：模型错误预测为正类的样本数。
    - **真负例（True Negative, TN）**：模型正确预测为负类的样本数。
    - **假负例（False Negative, FN）**：模型错误预测为负类的样本数。
- **准确率（Accuracy）**：模型预测正确的样本数占总样本数的比例，计算公式为：
    $$
    \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
    $$
- **精确率（Precision）**：被预测为正类的样本中，真正为正类的比例，计算公式为：
    $$
    \text{Precision} = \frac{TP}{TP + FP}
    $$
- **召回率（Recall）**：所有正类样本中，被正确预测为正类的比例，计算公式为：
    $$
    \text{Recall} = \frac{TP}{TP + FN}
    $$
- **F1分数（F1 Score）**：精确率和召回率的调和平均值，用于综合评估分类模型的性能，计算公式为：
    $$
    \text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
    $$
- **F2分数（F2 Score）**：更强调召回率的指标，计算公式为：
    $$
    \text{F2 Score} = 5 \times \frac{\text{Precision} \times \text{Recall}}{4 \times \text{Precision} + \text{Recall}}
    $$



## 机器学习常用模型
### 线性回归(LinearRegression)
- h(x)=w0+w1 * x1+w2 * x2+...
- 线性回归是机器学习中一个最基本的模型，它通过学习训练特征数据(w1,w2...)，来预测目标变量(h(x))。假设目标变量与特征之间存在线性关系，即可以用一个线性方程来表示这种关系。
- 误差项w0: 预测值与真实值之间的误差,是独立的,并具有相同的分,均值为0,方差值为参数平方的高斯分布
- 独立: 数据项直接不会互相影响
- 同分布: 数据尽可能来自同一个地方
- 高斯(正态)分布: 数据小范围浮动几率大,数据大范围浮动几率小
```python
from sklearn.linear_model import LinearRegression

# 创建线性回归模型对象
model = LinearRegression(
    fit_intercept=True,  # 是否计算截距（即 y = wx + b 中的 b）。默认为 True。
    copy_X=True,        # 是否复制 X（输入数据）。默认为 True。如果为 False，可能会覆盖原始数据。
    n_jobs=None,        # 用于计算的作业数。默认为 None，表示使用 1 个作业。如果为 -1，则使用所有可用的 CPU 核心。
    positive=False      # 是否强制系数为正。默认为 False。如果为 True，则强制系数为非负。
)

# 参数解释：
# - fit_intercept: 是否计算模型的截距。如果设置为 False，则模型不会计算截距（即 b = 0）。
# - copy_X: 是否复制输入数据 X。如果设置为 False，可能会在拟合过程中覆盖原始数据。
# - n_jobs: 用于并行计算的作业数。如果设置为 -1，则使用所有可用的 CPU 核心。
# - positive: 是否强制模型的系数为非负。如果设置为 True，则模型的系数将是非负的。

# 拟合模型
model.fit(X_train, y_train)

# 预测
predictions = model.predict(X_test)
print(predictions)  # 输出预测结果
```
#### 梯度下降优化算法
- 学习率(步长): 学习率是梯度下降算法中的一个重要参数，它控制着每次参数更新的步长。学习率越大，每次更新参数的步长越大，迭代次数越少，但同时可能会导致模型过拟合。学习率越小，每次更新参数的步长越小，迭代次数越多，但同时可能会导致模型欠拟合。
- 梯度下降的作用
梯度下降是一种迭代优化算法，用于找到目标函数的最小值。在机器学习中，目标函数通常是损失函数（如均方误差或交叉熵损失），而梯度下降通过调整模型参数来最小化这些损失函数。
- 梯度下降的工作原理
梯度下降的核心思想是利用目标函数的梯度（即导数）来指导参数的更新方向

- 具体步骤如下：
初始化参数：选择一个初始的参数值（通常是随机初始化）。
计算梯度：计算目标函数在当前参数下的梯度（即导数）。
更新参数：根据梯度的方向更新参数，使目标函数的值减小。
迭代：重复上述步骤，直到目标函数的值收敛到最小值。
```python
import numpy as np

# 生成示例数据
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# 添加偏置项（intercept）
X_b = np.c_[np.ones((100, 1)), X]

# 初始化参数
theta = np.random.randn(2, 1)

# 超参数
learning_rate = 0.1
n_iterations = 1000

# 梯度下降
for iteration in range(n_iterations):
    gradients = 2 / len(X_b) * X_b.T.dot(X_b.dot(theta) - y)
    theta = theta - learning_rate * gradients

# 输出最终参数
print("最优参数：", theta)

# 预测
X_new = np.array([[0], [2]])
X_new_b = np.c_[np.ones((2, 1)), X_new]
y_pred = X_new_b.dot(theta)
print("预测结果：", y_pred)
```
### 逻辑回归（Logistic Regression）
- 逻辑回归是机器学习中一个最基本的模型，是一种广泛应用于二分类问题的机器学习算法，尽管名字中有“回归”二字，但它实际上是一种分类算法。
```python
from sklearn.linear_model import LogisticRegression

# 创建逻辑回归模型对象
model = LogisticRegression(
    penalty='l2',              # 正则化类型，可选 'l1', 'l2', 'elasticnet', 'none'。默认为 'l2'。
    dual=False,                # 是否使用对偶形式。默认为 False。适用于样本数 > 特征数的情况。
    tol=1e-4,                  # 优化算法的收敛阈值。默认为 1e-4。
    C=1.0,                     # 正则化强度的倒数。C 越小，正则化越强。默认为 1.0。
    fit_intercept=True,        # 是否计算截距。默认为 True。
    intercept_scaling=1,       # 当使用正则化且 fit_intercept=True 时，缩放截距。默认为 1。
    class_weight=None,         # 类别权重。可以设置为 'balanced' 或字典形式。默认为 None。
    random_state=None,         # 随机种子，用于控制随机性。默认为 None。
    solver='lbfgs',            # 优化算法。可选 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'。默认为 'lbfgs'。
    max_iter=100,              # 最大迭代次数。默认为 100。
    multi_class='auto',        # 多分类策略。可选 'auto', 'ovr', 'multinomial'。默认为 'auto'。
    verbose=0,                 # 日志输出详细程度。默认为 0（不输出）。
    warm_start=False,          # 是否使用上一次训练的结果初始化。默认为 False。
    n_jobs=None,               # 并行计算作业数。默认为 None。
    l1_ratio=None              # Elastic-Net 混合参数（仅当 penalty='elasticnet' 时有效）。默认为 None。
)

# 参数解释：
# - penalty: 正则化类型。'l1' 和 'l2' 分别对应 L1 和 L2 正则化，'elasticnet' 是 L1 和 L2 的组合。
# - dual: 是否使用对偶形式。仅当 penalty='l2' 且 solver='liblinear' 时有效。
# - tol: 优化算法的收敛阈值。损失函数的变化小于该值时停止迭代。
# - C: 正则化强度的倒数。C 越小，正则化越强。
# - fit_intercept: 是否计算截距。
# - intercept_scaling: 当使用正则化且 fit_intercept=True 时，缩放截距。
# - class_weight: 类别权重。可以设置为 'balanced' 或字典形式，用于处理类别不平衡问题。
# - random_state: 随机种子，用于控制随机性。
# - solver: 优化算法。'lbfgs' 是默认算法，适用于大多数情况。
# - max_iter: 最大迭代次数。
# - multi_class: 多分类策略。'ovr' 是“一对多”，'multinomial' 是“多项式”。
# - verbose: 日志输出详细程度。
# - warm_start: 是否使用上一次训练的结果初始化。
# - n_jobs: 并行计算作业数。
# - l1_ratio: Elastic-Net 混合参数（仅当 penalty='elasticnet' 时有效）。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
### K近邻算法（K-Nearest Neighbors, KNN）
是一种简单而有效的分类和回归算法。它的核心思想是：对于一个未知样本，找到训练集中与其最接近的 \( k \) 个样本，然后根据这 \( k \) 个样本的类别（分类问题）或值（回归问题）来预测未知样本的类别或值。

在 `scikit-learn` 中，KNN 的实现由 `KNeighborsClassifier`（用于分类）和 `KNeighborsRegressor`（用于回归）提供。

**KNN 分类模型的参数**
```python
from sklearn.neighbors import KNeighborsClassifier

# 创建 KNN 分类模型对象
model = KNeighborsClassifier(
    n_neighbors=5,            # 使用的邻居数，默认为 5。
    weights='uniform',        # 权重函数。可选 'uniform'（等权重）或 'distance'（按距离加权）。默认为 'uniform'。
    algorithm='auto',         # 计算最近邻的算法。可选 'auto', 'ball_tree', 'kd_tree', 'brute'。默认为 'auto'。
    leaf_size=30,             # 传递给 BallTree 或 KDTree 的叶子大小。默认为 30。
    p=2,                      # 距离度量参数。p=1 为曼哈顿距离，p=2 为欧氏距离。默认为 2。
    metric='minkowski',       # 距离度量类型。默认为 'minkowski'（闵可夫斯基距离）。
    metric_params=None,       # 距离度量的额外参数。默认为 None。
    n_jobs=None               # 并行计算作业数。默认为 None。
)

# 参数解释：
# - n_neighbors: 使用的邻居数。k 值越小，模型越复杂；k 值越大，模型越简单。
# - weights: 权重函数。'uniform' 表示所有邻居的权重相等，'distance' 表示权重与距离成反比。
# - algorithm: 计算最近邻的算法。'auto' 自动选择最佳算法，'ball_tree' 和 'kd_tree' 适用于高维数据，'brute' 适用于低维数据。
# - leaf_size: 传递给 BallTree 或 KDTree 的叶子大小。影响树的构建和查询速度。
# - p: 距离度量参数。p=1 为曼哈顿距离，p=2 为欧氏距离。
# - metric: 距离度量类型。默认为 'minkowski'（闵可夫斯基距离）。
# - metric_params: 距离度量的额外参数。
# - n_jobs: 并行计算作业数。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
**KNN 回归模型的参数**
KNN 回归模型的参数与分类模型几乎相同，唯一的区别是它的目标值是连续值而不是类别。

```python
from sklearn.neighbors import KNeighborsRegressor

# 创建 KNN 回归模型对象
model = KNeighborsRegressor(
    n_neighbors=5,            # 使用的邻居数，默认为 5。
    weights='uniform',        # 权重函数。可选 'uniform'（等权重）或 'distance'（按距离加权）。默认为 'uniform'。
    algorithm='auto',         # 计算最近邻的算法。可选 'auto', 'ball_tree', 'kd_tree', 'brute'。默认为 'auto'。
    leaf_size=30,             # 传递给 BallTree 或 KDTree 的叶子大小。默认为 30。
    p=2,                      # 距离度量参数。p=1 为曼哈顿距离，p=2 为欧氏距离。默认为 2。
    metric='minkowski',       # 距离度量类型。默认为 'minkowski'（闵可夫斯基距离）。
    metric_params=None,       # 距离度量的额外参数。默认为 None。
    n_jobs=None               # 并行计算作业数。默认为 None。
)

# 示例数据
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成回归数据集
X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
### 决策树（Decision Tree）
是一种基于树结构的机器学习算法，既可以用于分类任务，也可以用于回归任务。它的核心思想是通过递归地划分数据集，构建一棵树，每个内部节点表示一个特征的分裂规则，每个叶节点表示一个类别（分类问题）或值（回归问题）。

决策树分类模型的参数
```python
from sklearn.tree import DecisionTreeClassifier

# 创建决策树分类模型对象
model = DecisionTreeClassifier(
    criterion='gini',          # 分裂标准。可选 'gini'（基尼系数）或 'entropy'（信息增益）。默认为 'gini'。
    splitter='best',           # 分裂策略。可选 'best'（最佳分裂）或 'random'（随机分裂）。默认为 'best'。
    max_depth=None,            # 树的最大深度。默认为 None，表示不限制深度。
    min_samples_split=2,       # 分裂内部节点所需的最小样本数。默认为 2。
    min_samples_leaf=1,        # 叶节点所需的最小样本数。默认为 1。
    min_weight_fraction_leaf=0.0,  # 叶节点所需的最小权重比例。默认为 0.0。
    max_features=None,         # 寻找最佳分裂时考虑的最大特征数。默认为 None，表示考虑所有特征。
    random_state=None,         # 随机种子，用于控制随机性。默认为 None。
    max_leaf_nodes=None,       # 最大叶节点数。默认为 None，表示不限制。
    min_impurity_decrease=0.0, # 分裂所需的最小不纯度减少量。默认为 0.0。
    class_weight=None,         # 类别权重。可以设置为 'balanced' 或字典形式。默认为 None。
    ccp_alpha=0.0              # 用于剪枝的复杂度参数。默认为 0.0。
)

# 参数解释：
# - criterion: 分裂标准。'gini' 使用基尼系数，'entropy' 使用信息增益。
# - splitter: 分裂策略。'best' 选择最佳分裂，'random' 选择随机分裂。
# - max_depth: 树的最大深度。限制树的深度可以防止过拟合。
# - min_samples_split: 分裂内部节点所需的最小样本数。
# - min_samples_leaf: 叶节点所需的最小样本数。
# - min_weight_fraction_leaf: 叶节点所需的最小权重比例。
# - max_features: 寻找最佳分裂时考虑的最大特征数。
# - random_state: 随机种子，用于控制随机性。
# - max_leaf_nodes: 最大叶节点数。
# - min_impurity_decrease: 分裂所需的最小不纯度减少量。
# - class_weight: 类别权重，用于处理类别不平衡问题。
# - ccp_alpha: 用于剪枝的复杂度参数。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
决策树回归模型的参数
```python
from sklearn.tree import DecisionTreeRegressor

# 创建决策树回归模型对象
model = DecisionTreeRegressor(
    criterion='squared_error',  # 分裂标准。可选 'squared_error'（均方误差）或 'friedman_mse'（改进的均方误差）。默认为 'squared_error'。
    splitter='best',           # 分裂策略。可选 'best'（最佳分裂）或 'random'（随机分裂）。默认为 'best'。
    max_depth=None,            # 树的最大深度。默认为 None，表示不限制深度。
    min_samples_split=2,       # 分裂内部节点所需的最小样本数。默认为 2。
    min_samples_leaf=1,        # 叶节点所需的最小样本数。默认为 1。
    min_weight_fraction_leaf=0.0,  # 叶节点所需的最小权重比例。默认为 0.0。
    max_features=None,         # 寻找最佳分裂时考虑的最大特征数。默认为 None，表示考虑所有特征。
    random_state=None,         # 随机种子，用于控制随机性。默认为 None。
    max_leaf_nodes=None,       # 最大叶节点数。默认为 None，表示不限制。
    min_impurity_decrease=0.0, # 分裂所需的最小不纯度减少量。默认为 0.0。
    ccp_alpha=0.0              # 用于剪枝的复杂度参数。默认为 0.0。
)

# 示例数据
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成回归数据集
X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
### 随机森林
通过多棵树+双重随机性学习，显著提升泛化能力，但牺牲了解释性和速度。
集成学习Bagging核心思想：通过自助采样（Bootstrap Sampling）生成多个子数据集，并行训练多个基学习器，最终通过投票（分类）或平均（回归）聚合结果。
```python
from sklearn.ensemble import RandomForestClassifier
# 处理回归问题 from sklearn.ensemble import RandomForestRegressor
# 创建随机森林模型实例
rf_model = RandomForestClassifier(
    n_estimators=100,       # 森林中树的数量，默认100。增加n_estimators通常会提高性能，但会增加计算成本
    criterion='gini',       # 分裂质量的衡量标准，'gini'或'entropy'。gini用于基尼不纯度，entropy用于信息增益
    max_depth=None,         # 树的最大深度。None表示节点扩展直到所有叶子纯净或包含少于min_samples_split样本
    min_samples_split=2,    # 分裂内部节点所需的最小样本数。可以是整数或浮点数(表示比例)
    min_samples_leaf=1,     # 叶节点所需的最小样本数。与min_samples_split类似，防止过拟合
    min_weight_fraction_leaf=0.0,  # 叶节点所需的权重总和的最小加权分数
    max_features='auto',    # 寻找最佳分割时要考虑的特征数量。可以是整数、浮点数或{'auto','sqrt','log2'}
                           # 'auto'和'sqrt'都表示max_features=sqrt(n_features)
                           # 'log2'表示max_features=log2(n_features)
    max_leaf_nodes=None,    # 以最佳优先方式生长树，None表示无限制叶节点数
    min_impurity_decrease=0.0,  # 如果分裂导致不纯度减少大于或等于该值，节点将被分裂
    bootstrap=True,         # 是否使用bootstrap样本构建树。False表示使用整个数据集构建每棵树
    oob_score=False,        # 是否使用袋外样本来估计泛化精度。需要bootstrap=True
    n_jobs=None,           # 并行运行的作业数。None表示1，-1表示使用所有处理器
    random_state=42,       # 控制随机性，使结果可重现
    verbose=0,             # 控制拟合和预测时的详细程度
    warm_start=False,      # 设置为True时，重用上一个调用的解决方案以适应更多估计器
    class_weight=None      # 类别的权重。None表示所有类别权重为1
                           # 'balanced'自动调整权重与输入数据中的类别频率成反比
)

# 训练模型
rf_model.fit(X_train, y_train)

# 使用模型进行预测
y_pred = rf_model.predict(X_test)

"""
模型训练后可访问的重要属性和方法：
"""

# 1. 特征重要性
print("特征重要性:", rf_model.feature_importances_)
# 返回每个特征的重要性(基于平均不纯度减少)

# 2. 袋外分数(如果oob_score=True)
if rf_model.oob_score:
    print("袋外估计准确率:", rf_model.oob_score_)

# 3. 决策树集合
print("森林中的树数量:", len(rf_model.estimators_))
# 可以通过rf_model.estimators_[i]访问单个决策树

# 4. 类别标签(分类问题)
print("类别标签:", rf_model.classes_)

# 5. 预测概率
print("预测概率:", rf_model.predict_proba(X_test[:5]))

# 6. 预测对数概率
print("预测对数概率:", rf_model.predict_log_proba(X_test[:5]))

"""
常用方法：
1. fit(X, y) - 训练模型
2. predict(X) - 预测类别
3. predict_proba(X) - 预测类别概率
4. score(X, y) - 返回平均准确度
5. apply(X) - 返回每个样本的叶节点索引
6. decision_path(X) - 返回决策路径
"""


```
### 支持向量机（Support Vector Machine, SVM）
是一种强大的监督学习算法，广泛用于分类和回归任务。它的核心思想是找到一个超平面，将不同类别的样本分开，并且最大化类别之间的边界（即“间隔”）。
SVC分类模型
```python
from sklearn.svm import SVC

# 创建 SVM 分类模型对象
model = SVC(
    C=1.0,                    # 正则化参数。C 越小，正则化越强。默认为 1.0。
    kernel='rbf',             # 核函数类型。可选 'linear', 'poly', 'rbf', 'sigmoid'。默认为 'rbf'。
    degree=3,                 # 多项式核函数的次数（仅当 kernel='poly' 时有效）。默认为 3。
    gamma='scale',            # 核函数的系数。可选 'scale', 'auto' 或具体数值。默认为 'scale'。
    coef0=0.0,                # 核函数中的独立项（仅当 kernel='poly' 或 'sigmoid' 时有效）。默认为 0.0。
    shrinking=True,           # 是否使用启发式收缩。默认为 True。
    probability=False,        # 是否启用概率估计。默认为 False。
    tol=1e-3,                 # 优化算法的收敛阈值。默认为 1e-3。
    cache_size=200,           # 核函数缓存大小（以 MB 为单位）。默认为 200。
    class_weight=None,        # 类别权重。可以设置为 'balanced' 或字典形式。默认为 None。
    verbose=False,            # 是否启用详细输出。默认为 False。
    max_iter=-1,              # 最大迭代次数。-1 表示无限制。默认为 -1。
    decision_function_shape='ovr',  # 决策函数形状。可选 'ovr'（一对多）或 'ovo'（一对一）。默认为 'ovr'。
    break_ties=False,         # 是否打破平局（仅当 decision_function_shape='ovr' 时有效）。默认为 False。
    random_state=None         # 随机种子，用于控制随机性。默认为 None。
)

# 参数解释：
# - C: 正则化参数。C 越小，正则化越强。
# - kernel: 核函数类型。'linear' 是线性核，'poly' 是多项式核，'rbf' 是径向基核，'sigmoid' 是 sigmoid 核。
# - degree: 多项式核函数的次数（仅当 kernel='poly' 时有效）。
# - gamma: 核函数的系数。'scale' 表示 1 / (n_features * X.var())，'auto' 表示 1 / n_features。
# - coef0: 核函数中的独立项（仅当 kernel='poly' 或 'sigmoid' 时有效）。
# - shrinking: 是否使用启发式收缩。
# - probability: 是否启用概率估计。
# - tol: 优化算法的收敛阈值。
# - cache_size: 核函数缓存大小（以 MB 为单位）。
# - class_weight: 类别权重，用于处理类别不平衡问题。
# - verbose: 是否启用详细输出。
# - max_iter: 最大迭代次数。-1 表示无限制。
# - decision_function_shape: 决策函数形状。'ovr' 是“一对多”，'ovo' 是“一对一”。
# - break_ties: 是否打破平局（仅当 decision_function_shape='ovr' 时有效）。
# - random_state: 随机种子，用于控制随机性。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)

```
SVR回归模型
```python
from sklearn.svm import SVR

# 创建 SVM 回归模型对象
model = SVR(
    kernel='rbf',             # 核函数类型。可选 'linear', 'poly', 'rbf', 'sigmoid'。默认为 'rbf'。
    degree=3,                 # 多项式核函数的次数（仅当 kernel='poly' 时有效）。默认为 3。
    gamma='scale',            # 核函数的系数。可选 'scale', 'auto' 或具体数值。默认为 'scale'。
    coef0=0.0,                # 核函数中的独立项（仅当 kernel='poly' 或 'sigmoid' 时有效）。默认为 0.0。
    tol=1e-3,                 # 优化算法的收敛阈值。默认为 1e-3。
    C=1.0,                    # 正则化参数。C 越小，正则化越强。默认为 1.0。
    epsilon=0.1,              # 控制回归模型的容忍度。默认为 0.1。
    shrinking=True,           # 是否使用启发式收缩。默认为 True。
    cache_size=200,           # 核函数缓存大小（以 MB 为单位）。默认为 200。
    verbose=False,            # 是否启用详细输出。默认为 False。
    max_iter=-1               # 最大迭代次数。-1 表示无限制。默认为 -1。
)

# 示例数据
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成回归数据集
X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```

## 模型评估


### 分类任务评估指标

#### 1. 准确率(Accuracy)
**含义**：分类正确的样本占总样本的比例。

```python
from sklearn.metrics import accuracy_score

y_true = [0, 1, 1, 0, 1]
y_pred = [0, 1, 0, 0, 1]
acc = accuracy_score(y_true, y_pred)
print(f"Accuracy: {acc:.2f}")
```

#### 2. 精确率(Precision)
**含义**：预测为正的样本中实际为正的比例。

```python
from sklearn.metrics import precision_score

precision = precision_score(y_true, y_pred)
print(f"Precision: {precision:.2f}")
```

#### 3. 召回率(Recall)
**含义**：实际为正的样本中被预测为正的比例。

```python
from sklearn.metrics import recall_score

recall = recall_score(y_true, y_pred)
print(f"Recall: {recall:.2f}")
```

#### 4. F1分数
**含义**：精确率和召回率的调和平均数。

```python
from sklearn.metrics import f1_score

f1 = f1_score(y_true, y_pred)
print(f"F1 Score: {f1:.2f}")
```

#### 5. ROC曲线和AUC
**含义**：反映分类器在不同阈值下的性能，AUC表示ROC曲线下的面积。

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

y_scores = [0.1, 0.9, 0.4, 0.2, 0.8]  # 预测概率
fpr, tpr, thresholds = roc_curve(y_true, y_scores)
auc = roc_auc_score(y_true, y_scores)

plt.plot(fpr, tpr)
plt.title(f'ROC Curve (AUC = {auc:.2f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.show()
```

#### 6. 混淆矩阵
**含义**：展示分类结果的详细情况。

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
```

### 回归任务评估指标

#### 1. 均方误差(MSE)
**含义**：预测值与真实值差值的平方的平均值。

```python
from sklearn.metrics import mean_squared_error

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
mse = mean_squared_error(y_true, y_pred)
print(f"MSE: {mse:.2f}")
```

#### 2. 均方根误差(RMSE)
**含义**：MSE的平方根，与目标变量单位一致。

```python
rmse = mean_squared_error(y_true, y_pred, squared=False)
print(f"RMSE: {rmse:.2f}")
```

#### 3. 平均绝对误差(MAE)
**含义**：预测值与真实值差值的绝对值的平均值。

```python
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_true, y_pred)
print(f"MAE: {mae:.2f}")
```

#### 4. R²决定系数
**含义**：反映模型对数据方差解释的比例，越接近1越好。

```python
from sklearn.metrics import r2_score

r2 = r2_score(y_true, y_pred)
print(f"R² Score: {r2:.2f}")
```

#### 5. 解释方差分数
**含义**：衡量模型对目标变量方差的解释能力。

```python
from sklearn.metrics import explained_variance_score

evs = explained_variance_score(y_true, y_pred)
print(f"Explained Variance Score: {evs:.2f}")
```

### 选择评估指标的考虑因素

1. **分类任务**：
   - 类别平衡：准确率在不平衡数据中可能误导，应考虑F1、AUC等
   - 错误代价：如果假阳性/假阴性代价不同，应侧重精确率或召回率

2. **回归任务**：
   - 异常值影响：MSE对异常值更敏感，MAE更鲁棒
   - 解释性：R²更容易解释模型性能

---

## 模型调优
### 网格搜索(GridSearchCV)
`GridSearchCV` 是 scikit-learn 中用于超参数调优的重要工具，它通过交叉验证的方式系统地遍历所有给定的参数组合，寻找最优模型配置。下面我将详细解释其使用方法、关键参数作用及设置技巧。

#### **1. GridSearchCV 核心参数详解**
**基本参数**
| 参数 | 作用 | 常用设置 | 注意事项 |
|------|------|----------|----------|
| `estimator` | 待调优的模型对象 | `SVR()`, `RandomForestClassifier()` | 需先初始化一个基础模型 |
| `param_grid` | 参数搜索空间 | 字典或列表格式（见下文） | 关键调优部分 |
| `scoring` | 评估指标 | `'accuracy'`, `'r2'`, `'neg_mean_squared_error'` | 支持自定义指标 |
| `cv` | 交叉验证策略 | 整数（如 `5`）或交叉验证生成器 | 通常 5 或 10 折 |
| `refit` | 是否用最优参数重新拟合模型 | `True`（默认）或指定指标名 | 训练后可直接用 `best_estimator_` 预测 |
| `verbose` | 日志详细程度 | `0`（静默）到 `3`（详细） | 调试时可设为 2 |
| `n_jobs` | 并行计算数 | `-1`（使用所有CPU核心） | 加速搜索，但内存不足时需谨慎 |
| `return_train_score` | 是否返回训练集分数 | `True`/`False` | 可用于检查过拟合 |

**总结**
- **`param_grid`**：定义搜索空间，决定调优范围。
- **`scoring`**：选择与任务匹配的评估指标（如回归用 `'r2'`）。
- **`cv`**：控制交叉验证的严谨性（常用 5 或 10 折）。
- **`refit`**：训练结束后自动用最优参数重新拟合模型。
- **`n_jobs`**：加速搜索，但需注意内存限制。
通过合理设置这些参数，`GridSearchCV` 可以高效地找到最优模型配置，显著提升预测性能。
#### **2. `param_grid` 参数网格设置**
定义需要搜索的超参数组合，支持两种格式：
**(1) 字典格式（常用）**
```python
param_grid = {
    'kernel': ['linear', 'rbf'],
    'C': [0.1, 1, 10],
    'gamma': ['scale', 'auto', 0.1]
}
```
- **搜索所有组合**：共 2（kernel） × 3（C） × 3（gamma） = 18 种组合。

**(2) 列表格式（并行搜索多个网格）**
```python
param_grid = [
    {'kernel': ['linear'], 'C': [0.1, 1]},
    {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.1, 1]}
]
```
- **先搜索第一个字典**（线性核，2种组合），**再搜索第二个字典**（RBF核，2×2=4种组合），共 6 种组合。


#### **3. `scoring` 评估指标设置**
**内置指标**
- **分类任务**：`'accuracy'`, `'f1'`, `'roc_auc'` 等
- **回归任务**：`'r2'`, `'neg_mean_squared_error'`（MSE的负值）

```python
# 单指标评估
scoring = 'r2'  # 以 R² 作为优化目标
# 多指标评估
scoring = {
    'R2': 'r2',
    'MSE': 'neg_mean_squared_error',
    'RMSE': make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)))
}
```

**自定义指标**
```python
from sklearn.metrics import make_scorer

def custom_loss(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred))

scoring = make_scorer(custom_loss, greater_is_better=False)
```

---

#### **4. `cv` 交叉验证策略**
**(1) 整数指定折数**
```python
cv = 5  # 5 折交叉验证
```

**(2) 自定义交叉验证生成器**
```python
from sklearn.model_selection import KFold
cv = KFold(n_splits=5, shuffle=True, random_state=42)
```

**(3) 分层交叉验证（分类任务）**
```python
from sklearn.model_selection import StratifiedKFold
cv = StratifiedKFold(n_splits=5)
```


#### **5. 完整使用示例（以 SVR 为例）**
```python

### **步骤 1：导入库并准备数据**
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# 假设已有数据 X 和 y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

### **步骤 2：定义参数网格**
param_grid = {
    'kernel': ['linear', 'rbf', 'poly'],
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.1, 1],
    'epsilon': [0.01, 0.1, 0.5]
}

### **步骤 3：初始化 GridSearchCV**
svr = SVR()
grid_search = GridSearchCV(
    estimator=svr,
    param_grid=param_grid,
    scoring='r2',      # 以 R² 作为优化目标
    cv=5,              # 5 折交叉验证
    verbose=2,         # 打印进度
    n_jobs=-1,         # 使用所有 CPU 核心
    return_train_score=True  # 保存训练集分数
)

### **步骤 4：执行网格搜索**
grid_search.fit(X_train, y_train)

### **步骤 5：分析结果**
# 最优参数
print("Best parameters:", grid_search.best_params_)

# 最优模型
best_svr = grid_search.best_estimator_

# 在测试集上评估
y_pred = best_svr.predict(X_test)
print("R²:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

### **步骤 6：查看所有参数组合结果**
results = pd.DataFrame(grid_search.cv_results_)
print(results[['params', 'mean_test_score', 'std_test_score']])
```

## **6. 关键注意事项**
1. **计算资源管理**：
   - 参数组合数 = `param_grid` 所有可能的组合数 × `cv` 折数。
   - 若组合太多（如 >1000），可改用 `RandomizedSearchCV` 随机搜索。

2. **过拟合检查**：
   - 如果 `train_score` 远高于 `test_score`，说明可能过拟合，需调整 `C` 或 `gamma`。

3. **数据标准化**：
   - SVR 对特征尺度敏感，建议提前用 `StandardScaler` 标准化数据。

4. **并行化问题**：
   - `n_jobs=-1` 可能占用大量内存，若内存不足可设为 `1` 或 `2`。




## 训练模型的步骤
训练模型的完整步骤：

问题定义：明确任务类型（分类、回归、聚类等）和评估指标。

数据准备：收集数据、处理缺失值、异常值、重复值。

特征工程：特征编码、标准化/归一化、特征选择、降维（如PCA）。

数据划分：将数据集划分为训练集、验证集和测试集（常用比例如 7:3 或 8:2）。

模型选择：根据任务类型选择算法（如线性回归、决策树、SVM）。

模型训练：在训练集上拟合模型，调整参数（如学习率、正则化系数）。

模型评估：在验证集上评估性能（如MSE、R²、准确率），分析过拟合/欠拟合。

模型调优：通过网格搜索、随机搜索或贝叶斯优化调整超参数。

最终评估：在测试集上测试模型泛化能力。

部署与监控：部署模型并持续监控性能。
