# 深度学习基础

## 环境搭建
1. 安装Python

2. 安装Anaconda(miniconda)
```sh
# 使用conda管理虚拟环境

# 创建虚拟环境
conda create -n `env-name` `python=版本` [-c 镜像地址]
# 删除建虚拟环境
conda remove -n `env-name` --all
# 添加源
# channels:
#   - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
#   - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
#   - https://mirrors.ustc.edu.cn/anaconda/pkgs/free
#   - https://mirrors.ustc.edu.cn/anaconda/pkgs/main

conda config --add channels 通道地址
# 删除源
conda config --remove channels 通道地址
# 查看源
conda config --show channels
# 安装时显示安装源
conda config --set show_channel_urls yes


# 查看环境列表
conda env list

# 配置powershell正确显示(环境名)
conda init powershell
conda config --set auto_activate_base false



#激活某个虚拟环境(*)
conda activate env_name
# 退出某个虚拟环境(*)
conda deactivate

# 使用pip安装/卸载虚拟环境包
pip install/uninstall 包[=版本号] [-i 源链接]

pip install -r "requirements.txt文件" [-i 源]
# 更新包
pip install --upgrade 包
#查看安装的包 
pip list

# conda install/uninstall 包名[=版本号] [-i 源链接]
```
3. 安装CUDA驱动/运行环境
```sh
# 1. 确定显卡为Nvidia系列
Windows: 使用组合键`Ctrl+Shift+ESC`打开任务管理器，选择`性能`->`GPU1`查看显卡型号

# 2. 安装显卡驱动
官网安装

# 3. 安装CUDA
确定cuda最高版本  nvidia-smi # 或 打开Nvidia控制面板->系统信息->组件
安装 conda install cuda -c nvidia/label/cuda-版本 #或 官网安装
检查安装是否成功 nvcc --version 

# 4. 安装cuDNN
确定cudnn版本 conda search cudnn --info # 或 官网查询
安装 conda install cudaa=版本 
验证安装 nvidia-smi 

```
4. Windows安装pytorch和cudnn
```url 
安装地址:
https://pytorch.org/get-started/locally/
```
```sh
# 激活conda环境


# conda安装 -c 镜像源
#cpu版本
conda install pytorch torchvision torchaudio cpuonly -c pytorch
# cuda版本 # 如果未安装cuda和cudnn会自动安装
conda install pytorch torchvision torchaudio pytorch-cuda=版本号 -c pytorch -c nvidia


# pip安装

#cpu版本
pip3 install torch torchvision torchaudio
# cuda版本  #如果未安装cuda和cudnn会自动安装
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu版本号

```
5. 创建Tensorflow环境
```python
conda create -n tensorflow_env python=3.9
conda activate tensorflow_env
pip install tensorflow==1.13.1
pip install keras==2.2.4
pip install matplotlib
pip install opencv-python
pip install numpy
```

6. 常用数据集
```
飞桨数据集 https://aistudio.baidu.com/datasetoverview
kaggle数据集 https://www.kaggle.com/datasets
```

## 常见名词
```
- 模型: 模型是学习算法，用来学习训练数据的过程，目的是让模型能够根据输入数据（特征）准确地预测输出结果（目标变量）
- 分类问题: 分类问题，即给定一个样本，预测样本属于某一个类别。(0,1)
- 回归问题: 回归问题，即给定一个样本，预测样本的连续值。(0,∞)
- 拟合（Fitting）是指模型学习训练数据的过程，目的是让模型能够根据输入数据（特征）准确地预测输出结果（目标变量）
-过拟合: 当模型在训练集上拟合效果好，但泛化到测试集时性能很差，则称模型为过拟合
欠拟合: 当模型在训练集上拟合效果不好，泛化到测试集时性能很差，则称模型为欠拟合
- 似然函数:似然函数（Likelihood Function）是统计学和机器学习中一个非常重要的概念，它描述了在给定一组参数下，观测到特定数据的概率。似然函数通常用于参数估计和模型选择。
- Loss函数:是一个衡量模型预测值与真实值之间差异的函数。损失函数的值越小，表示模型的预测结果越接近真实值，模型的性能越好。
```

## 机器学习常用模型
### 线性回归(LinearRegression)
- h(x)=w0+w1*x1+w2*x2+...
- 线性回归是机器学习中一个最基本的模型，它通过学习训练特征数据(w1,w2...)，来预测目标变量(h(x))。假设目标变量与特征之间存在线性关系，即可以用一个线性方程来表示这种关系。
- 误差项w0: 预测值与真实值之间的误差,是独立的,并具有相同的分,均值为0,方差值为参数平方的高斯分布
- 独立: 数据项直接不会互相影响
- 同分布: 数据尽可能来自同一个地方
- 高斯(正态)分布: 数据小范围浮动几率大,数据大范围浮动几率小
```python
from sklearn.linear_model import LinearRegression

# 创建线性回归模型对象
model = LinearRegression(
    fit_intercept=True,  # 是否计算截距（即 y = wx + b 中的 b）。默认为 True。
    copy_X=True,        # 是否复制 X（输入数据）。默认为 True。如果为 False，可能会覆盖原始数据。
    n_jobs=None,        # 用于计算的作业数。默认为 None，表示使用 1 个作业。如果为 -1，则使用所有可用的 CPU 核心。
    positive=False      # 是否强制系数为正。默认为 False。如果为 True，则强制系数为非负。
)

# 参数解释：
# - fit_intercept: 是否计算模型的截距。如果设置为 False，则模型不会计算截距（即 b = 0）。
# - copy_X: 是否复制输入数据 X。如果设置为 False，可能会在拟合过程中覆盖原始数据。
# - n_jobs: 用于并行计算的作业数。如果设置为 -1，则使用所有可用的 CPU 核心。
# - positive: 是否强制模型的系数为非负。如果设置为 True，则模型的系数将是非负的。

# 拟合模型
model.fit(X_train, y_train)

# 预测
predictions = model.predict(X_test)
print(predictions)  # 输出预测结果
```
#### 梯度下降优化算法
- 学习率(步长): 学习率是梯度下降算法中的一个重要参数，它控制着每次参数更新的步长。学习率越大，每次更新参数的步长越大，迭代次数越少，但同时可能会导致模型过拟合。学习率越小，每次更新参数的步长越小，迭代次数越多，但同时可能会导致模型欠拟合。
- 梯度下降的作用
梯度下降是一种迭代优化算法，用于找到目标函数的最小值。在机器学习中，目标函数通常是损失函数（如均方误差或交叉熵损失），而梯度下降通过调整模型参数来最小化这些损失函数。
- 梯度下降的工作原理
梯度下降的核心思想是利用目标函数的梯度（即导数）来指导参数的更新方向

- 具体步骤如下：
初始化参数：选择一个初始的参数值（通常是随机初始化）。
计算梯度：计算目标函数在当前参数下的梯度（即导数）。
更新参数：根据梯度的方向更新参数，使目标函数的值减小。
迭代：重复上述步骤，直到目标函数的值收敛到最小值。
### 逻辑回归（Logistic Regression）
- 逻辑回归是机器学习中一个最基本的模型，是一种广泛应用于二分类问题的机器学习算法，尽管名字中有“回归”二字，但它实际上是一种分类算法。
```python
from sklearn.linear_model import LogisticRegression

# 创建逻辑回归模型对象
model = LogisticRegression(
    penalty='l2',              # 正则化类型，可选 'l1', 'l2', 'elasticnet', 'none'。默认为 'l2'。
    dual=False,                # 是否使用对偶形式。默认为 False。适用于样本数 > 特征数的情况。
    tol=1e-4,                  # 优化算法的收敛阈值。默认为 1e-4。
    C=1.0,                     # 正则化强度的倒数。C 越小，正则化越强。默认为 1.0。
    fit_intercept=True,        # 是否计算截距。默认为 True。
    intercept_scaling=1,       # 当使用正则化且 fit_intercept=True 时，缩放截距。默认为 1。
    class_weight=None,         # 类别权重。可以设置为 'balanced' 或字典形式。默认为 None。
    random_state=None,         # 随机种子，用于控制随机性。默认为 None。
    solver='lbfgs',            # 优化算法。可选 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'。默认为 'lbfgs'。
    max_iter=100,              # 最大迭代次数。默认为 100。
    multi_class='auto',        # 多分类策略。可选 'auto', 'ovr', 'multinomial'。默认为 'auto'。
    verbose=0,                 # 日志输出详细程度。默认为 0（不输出）。
    warm_start=False,          # 是否使用上一次训练的结果初始化。默认为 False。
    n_jobs=None,               # 并行计算作业数。默认为 None。
    l1_ratio=None              # Elastic-Net 混合参数（仅当 penalty='elasticnet' 时有效）。默认为 None。
)

# 参数解释：
# - penalty: 正则化类型。'l1' 和 'l2' 分别对应 L1 和 L2 正则化，'elasticnet' 是 L1 和 L2 的组合。
# - dual: 是否使用对偶形式。仅当 penalty='l2' 且 solver='liblinear' 时有效。
# - tol: 优化算法的收敛阈值。损失函数的变化小于该值时停止迭代。
# - C: 正则化强度的倒数。C 越小，正则化越强。
# - fit_intercept: 是否计算截距。
# - intercept_scaling: 当使用正则化且 fit_intercept=True 时，缩放截距。
# - class_weight: 类别权重。可以设置为 'balanced' 或字典形式，用于处理类别不平衡问题。
# - random_state: 随机种子，用于控制随机性。
# - solver: 优化算法。'lbfgs' 是默认算法，适用于大多数情况。
# - max_iter: 最大迭代次数。
# - multi_class: 多分类策略。'ovr' 是“一对多”，'multinomial' 是“多项式”。
# - verbose: 日志输出详细程度。
# - warm_start: 是否使用上一次训练的结果初始化。
# - n_jobs: 并行计算作业数。
# - l1_ratio: Elastic-Net 混合参数（仅当 penalty='elasticnet' 时有效）。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
### K近邻算法（K-Nearest Neighbors, KNN）
是一种简单而有效的分类和回归算法。它的核心思想是：对于一个未知样本，找到训练集中与其最接近的 \( k \) 个样本，然后根据这 \( k \) 个样本的类别（分类问题）或值（回归问题）来预测未知样本的类别或值。

在 `scikit-learn` 中，KNN 的实现由 `KNeighborsClassifier`（用于分类）和 `KNeighborsRegressor`（用于回归）提供。

**KNN 分类模型的参数**
```python
from sklearn.neighbors import KNeighborsClassifier

# 创建 KNN 分类模型对象
model = KNeighborsClassifier(
    n_neighbors=5,            # 使用的邻居数，默认为 5。
    weights='uniform',        # 权重函数。可选 'uniform'（等权重）或 'distance'（按距离加权）。默认为 'uniform'。
    algorithm='auto',         # 计算最近邻的算法。可选 'auto', 'ball_tree', 'kd_tree', 'brute'。默认为 'auto'。
    leaf_size=30,             # 传递给 BallTree 或 KDTree 的叶子大小。默认为 30。
    p=2,                      # 距离度量参数。p=1 为曼哈顿距离，p=2 为欧氏距离。默认为 2。
    metric='minkowski',       # 距离度量类型。默认为 'minkowski'（闵可夫斯基距离）。
    metric_params=None,       # 距离度量的额外参数。默认为 None。
    n_jobs=None               # 并行计算作业数。默认为 None。
)

# 参数解释：
# - n_neighbors: 使用的邻居数。k 值越小，模型越复杂；k 值越大，模型越简单。
# - weights: 权重函数。'uniform' 表示所有邻居的权重相等，'distance' 表示权重与距离成反比。
# - algorithm: 计算最近邻的算法。'auto' 自动选择最佳算法，'ball_tree' 和 'kd_tree' 适用于高维数据，'brute' 适用于低维数据。
# - leaf_size: 传递给 BallTree 或 KDTree 的叶子大小。影响树的构建和查询速度。
# - p: 距离度量参数。p=1 为曼哈顿距离，p=2 为欧氏距离。
# - metric: 距离度量类型。默认为 'minkowski'（闵可夫斯基距离）。
# - metric_params: 距离度量的额外参数。
# - n_jobs: 并行计算作业数。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
**KNN 回归模型的参数**
KNN 回归模型的参数与分类模型几乎相同，唯一的区别是它的目标值是连续值而不是类别。

```python
from sklearn.neighbors import KNeighborsRegressor

# 创建 KNN 回归模型对象
model = KNeighborsRegressor(
    n_neighbors=5,            # 使用的邻居数，默认为 5。
    weights='uniform',        # 权重函数。可选 'uniform'（等权重）或 'distance'（按距离加权）。默认为 'uniform'。
    algorithm='auto',         # 计算最近邻的算法。可选 'auto', 'ball_tree', 'kd_tree', 'brute'。默认为 'auto'。
    leaf_size=30,             # 传递给 BallTree 或 KDTree 的叶子大小。默认为 30。
    p=2,                      # 距离度量参数。p=1 为曼哈顿距离，p=2 为欧氏距离。默认为 2。
    metric='minkowski',       # 距离度量类型。默认为 'minkowski'（闵可夫斯基距离）。
    metric_params=None,       # 距离度量的额外参数。默认为 None。
    n_jobs=None               # 并行计算作业数。默认为 None。
)

# 示例数据
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成回归数据集
X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
### 决策树（Decision Tree）
是一种基于树结构的机器学习算法，既可以用于分类任务，也可以用于回归任务。它的核心思想是通过递归地划分数据集，构建一棵树，每个内部节点表示一个特征的分裂规则，每个叶节点表示一个类别（分类问题）或值（回归问题）。

决策树分类模型的参数
```python
from sklearn.tree import DecisionTreeClassifier

# 创建决策树分类模型对象
model = DecisionTreeClassifier(
    criterion='gini',          # 分裂标准。可选 'gini'（基尼系数）或 'entropy'（信息增益）。默认为 'gini'。
    splitter='best',           # 分裂策略。可选 'best'（最佳分裂）或 'random'（随机分裂）。默认为 'best'。
    max_depth=None,            # 树的最大深度。默认为 None，表示不限制深度。
    min_samples_split=2,       # 分裂内部节点所需的最小样本数。默认为 2。
    min_samples_leaf=1,        # 叶节点所需的最小样本数。默认为 1。
    min_weight_fraction_leaf=0.0,  # 叶节点所需的最小权重比例。默认为 0.0。
    max_features=None,         # 寻找最佳分裂时考虑的最大特征数。默认为 None，表示考虑所有特征。
    random_state=None,         # 随机种子，用于控制随机性。默认为 None。
    max_leaf_nodes=None,       # 最大叶节点数。默认为 None，表示不限制。
    min_impurity_decrease=0.0, # 分裂所需的最小不纯度减少量。默认为 0.0。
    class_weight=None,         # 类别权重。可以设置为 'balanced' 或字典形式。默认为 None。
    ccp_alpha=0.0              # 用于剪枝的复杂度参数。默认为 0.0。
)

# 参数解释：
# - criterion: 分裂标准。'gini' 使用基尼系数，'entropy' 使用信息增益。
# - splitter: 分裂策略。'best' 选择最佳分裂，'random' 选择随机分裂。
# - max_depth: 树的最大深度。限制树的深度可以防止过拟合。
# - min_samples_split: 分裂内部节点所需的最小样本数。
# - min_samples_leaf: 叶节点所需的最小样本数。
# - min_weight_fraction_leaf: 叶节点所需的最小权重比例。
# - max_features: 寻找最佳分裂时考虑的最大特征数。
# - random_state: 随机种子，用于控制随机性。
# - max_leaf_nodes: 最大叶节点数。
# - min_impurity_decrease: 分裂所需的最小不纯度减少量。
# - class_weight: 类别权重，用于处理类别不平衡问题。
# - ccp_alpha: 用于剪枝的复杂度参数。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
决策树回归模型的参数
```python
from sklearn.tree import DecisionTreeRegressor

# 创建决策树回归模型对象
model = DecisionTreeRegressor(
    criterion='squared_error',  # 分裂标准。可选 'squared_error'（均方误差）或 'friedman_mse'（改进的均方误差）。默认为 'squared_error'。
    splitter='best',           # 分裂策略。可选 'best'（最佳分裂）或 'random'（随机分裂）。默认为 'best'。
    max_depth=None,            # 树的最大深度。默认为 None，表示不限制深度。
    min_samples_split=2,       # 分裂内部节点所需的最小样本数。默认为 2。
    min_samples_leaf=1,        # 叶节点所需的最小样本数。默认为 1。
    min_weight_fraction_leaf=0.0,  # 叶节点所需的最小权重比例。默认为 0.0。
    max_features=None,         # 寻找最佳分裂时考虑的最大特征数。默认为 None，表示考虑所有特征。
    random_state=None,         # 随机种子，用于控制随机性。默认为 None。
    max_leaf_nodes=None,       # 最大叶节点数。默认为 None，表示不限制。
    min_impurity_decrease=0.0, # 分裂所需的最小不纯度减少量。默认为 0.0。
    ccp_alpha=0.0              # 用于剪枝的复杂度参数。默认为 0.0。
)

# 示例数据
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成回归数据集
X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```
### 支持向量机（Support Vector Machine, SVM）
是一种强大的监督学习算法，广泛用于分类和回归任务。它的核心思想是找到一个超平面，将不同类别的样本分开，并且最大化类别之间的边界（即“间隔”）。
SVC分类模型
```python
from sklearn.svm import SVC

# 创建 SVM 分类模型对象
model = SVC(
    C=1.0,                    # 正则化参数。C 越小，正则化越强。默认为 1.0。
    kernel='rbf',             # 核函数类型。可选 'linear', 'poly', 'rbf', 'sigmoid'。默认为 'rbf'。
    degree=3,                 # 多项式核函数的次数（仅当 kernel='poly' 时有效）。默认为 3。
    gamma='scale',            # 核函数的系数。可选 'scale', 'auto' 或具体数值。默认为 'scale'。
    coef0=0.0,                # 核函数中的独立项（仅当 kernel='poly' 或 'sigmoid' 时有效）。默认为 0.0。
    shrinking=True,           # 是否使用启发式收缩。默认为 True。
    probability=False,        # 是否启用概率估计。默认为 False。
    tol=1e-3,                 # 优化算法的收敛阈值。默认为 1e-3。
    cache_size=200,           # 核函数缓存大小（以 MB 为单位）。默认为 200。
    class_weight=None,        # 类别权重。可以设置为 'balanced' 或字典形式。默认为 None。
    verbose=False,            # 是否启用详细输出。默认为 False。
    max_iter=-1,              # 最大迭代次数。-1 表示无限制。默认为 -1。
    decision_function_shape='ovr',  # 决策函数形状。可选 'ovr'（一对多）或 'ovo'（一对一）。默认为 'ovr'。
    break_ties=False,         # 是否打破平局（仅当 decision_function_shape='ovr' 时有效）。默认为 False。
    random_state=None         # 随机种子，用于控制随机性。默认为 None。
)

# 参数解释：
# - C: 正则化参数。C 越小，正则化越强。
# - kernel: 核函数类型。'linear' 是线性核，'poly' 是多项式核，'rbf' 是径向基核，'sigmoid' 是 sigmoid 核。
# - degree: 多项式核函数的次数（仅当 kernel='poly' 时有效）。
# - gamma: 核函数的系数。'scale' 表示 1 / (n_features * X.var())，'auto' 表示 1 / n_features。
# - coef0: 核函数中的独立项（仅当 kernel='poly' 或 'sigmoid' 时有效）。
# - shrinking: 是否使用启发式收缩。
# - probability: 是否启用概率估计。
# - tol: 优化算法的收敛阈值。
# - cache_size: 核函数缓存大小（以 MB 为单位）。
# - class_weight: 类别权重，用于处理类别不平衡问题。
# - verbose: 是否启用详细输出。
# - max_iter: 最大迭代次数。-1 表示无限制。
# - decision_function_shape: 决策函数形状。'ovr' 是“一对多”，'ovo' 是“一对一”。
# - break_ties: 是否打破平局（仅当 decision_function_shape='ovr' 时有效）。
# - random_state: 随机种子，用于控制随机性。

# 示例数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)

```
SVR回归模型
```python
from sklearn.svm import SVR

# 创建 SVM 回归模型对象
model = SVR(
    kernel='rbf',             # 核函数类型。可选 'linear', 'poly', 'rbf', 'sigmoid'。默认为 'rbf'。
    degree=3,                 # 多项式核函数的次数（仅当 kernel='poly' 时有效）。默认为 3。
    gamma='scale',            # 核函数的系数。可选 'scale', 'auto' 或具体数值。默认为 'scale'。
    coef0=0.0,                # 核函数中的独立项（仅当 kernel='poly' 或 'sigmoid' 时有效）。默认为 0.0。
    tol=1e-3,                 # 优化算法的收敛阈值。默认为 1e-3。
    C=1.0,                    # 正则化参数。C 越小，正则化越强。默认为 1.0。
    epsilon=0.1,              # 控制回归模型的容忍度。默认为 0.1。
    shrinking=True,           # 是否使用启发式收缩。默认为 True。
    cache_size=200,           # 核函数缓存大小（以 MB 为单位）。默认为 200。
    verbose=False,            # 是否启用详细输出。默认为 False。
    max_iter=-1               # 最大迭代次数。-1 表示无限制。默认为 -1。
)

# 示例数据
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成回归数据集
X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 拟合模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 输出预测结果
print("预测结果:", y_pred)
```

## 训练模型的步骤
训练模型的完整步骤：

问题定义：明确任务类型（分类、回归、聚类等）和评估指标。

数据准备：收集数据、处理缺失值、异常值、重复值。

特征工程：特征编码、标准化/归一化、特征选择、降维（如PCA）。

数据划分：将数据集划分为训练集、验证集和测试集（常用比例如 7:3 或 8:2）。

模型选择：根据任务类型选择算法（如线性回归、决策树、SVM）。

模型训练：在训练集上拟合模型，调整参数（如学习率、正则化系数）。

模型评估：在验证集上评估性能（如MSE、R²、准确率），分析过拟合/欠拟合。

模型调优：通过网格搜索、随机搜索或贝叶斯优化调整超参数。

最终评估：在测试集上测试模型泛化能力。

部署与监控：部署模型并持续监控性能。
